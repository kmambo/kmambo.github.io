= kMambo

_A cloud-native task management and orchestration system_

== Overview

kMambo runs``jobs`` in a Kubernetes cluster.
Each `job` is composed of one or more ``tasks``.

A `task` is the smallest unit of work in a kMambo job and runs as a microservice.
To start a ``task``, you have to provide it with data - some would prefer to call it an `event`.
The data may be "pushed" to the `task` - for example, by way of an HTTP POST; or it may be "pulled" - for example, the data may be queued to a Redis queue or Kafka or GCP PubSub and the `task` will read from the queue when it is ready to read the data.
In this latter respect, it differentiates itself from https://xxx[kNative]
Once a ``task`` is triggered, it consumes the data and produces an output data which can be used to trigger the next `task` in the `job`.
As per usual, the output data can be "pushed" to or "pulled by" the next `task` in the job.
A kMambo `task` only cares about the data it is supposed to work on.
It cares not for who or what produced this data.
It also does not care who will consume the output data it creates.

A kMambo `job` is programmable.

- It does not specify a static sequence of `tasks`.
If anything, it allows conditional statements like `if-then-else` to specify the sequence of `tasks` in a `job`.
- It is possible to program to source of the data that triggers `tasks` and the destination of the output data
- Retry logic for a `task` is programmable.
- kMambo also handles `task` definition updates and graceful or abrupt `task` cancellations.

== Example

Picture a car company with a fleet of cars where sensors collect all sorts of data from their cars: periodic tire pressure measurements, fuel measurements, engine temperature measurements etc.

- The data is likely to be collected by each car and bundled together and pushed to the car company's cloud deployment, where it is collected in a data lake.
- Before the data can be persisted, depending on the privacy requirements of various jurisdictions, personally identifiable information (PII) may have to be stripped out.
- Additionally, non-PII information like vehicle location or speed may also need to be stripped out.
- Then, the persisted data is collectively analyzed for patterns to detect conditions like fuel mileage variations in different models and years of the cars.


image::kmambo-components-kMambo_components_example___Data_Plane.png[]

In the image above,

. IoT devices in the field - embedded in cars in our case - collect all sorts of telemetry data and push to the Kubernetes cluster.
. The devices use HTTP for this push through an ingress controller.
. The ingress controller routes the incoming data to the `Data Ingestion Service` which round-robins the HTTP data to the pods of `Data Ingestion Task` which is a stateless replicaset.
These pods' only job is to quickly read, validate and queue the incoming data to the `Redis Queue`.
. It is from here that the pods of the replicaset `Post Ingestion Data Filters` read from the `Redis Queue` do the task of filtering out any data that is not allowed to keep - such as speed and location - and writes the remaining data to a data lake.


